\aufgabe{"Improving" Explanation Results}{

Your employer, E-Corp, has set up a new special task force, which you are part of. The goal of the task force is to increase the trust of individuals into the AI tools that the company sells to a wide range of businesses, governments and individuals.\\
The task force was set up as a reaction to criticism of its top-selling AI detection system \textit{Saruman's stone}. The goal of the system is to distinguish innocent civilians from targets in AWS\footnote{Here, AWS stands for autonomous weapon systems} scenarios.\\ %For instance, the "innocent civilian protection system" was employed to protect the president of the USA, Mr. Drumpf, against "enemies of the country" (people in a demonstration). At this event mostly non-white "enemies of the state" were imprisoned by the drones.\\
As a first measure to increase trust, you were asked to apply common explanation techniques like SHAP and LIME to the aforementioned AI model.
In contrast to the model and the data, which are well kept company secrets,\footnote{E-Corp wants to prevent evil terrorists from exploiting the knowledge to harm innocent civilians and especially children.} the results of your interpretations will be communicated to a board of independent journalists.\\
In your mission to increase trust and advance the progress of AI you have the clear task to avoid results that may undermine the progress of E-Corp or the adoption of Saruman's stone.\\

%$$f(x) = 0.1 beard + 0.1 skin + clothing + 0.5 arms$$
%
%\textit{beard}, \textit{skin}, \textit{military clothing}, \textit{arms}

Now it is up to you to save AI!

\begin{enumerate}
    \item Build groups of 2-3 people.
    \item Fit a random forest classifier with default hyperparameters on the dataset \texttt{data.csv}.
    \item Apply SHAP and LIME with default hyperparameters to the dataset. Interpret the results. Which conclusions do you draw (you can use \href{}{shaper} for R and \href{https://github.com/slundberg/shap}{shap} for python)?
    \item Since your mission is to increase trust in AI systems, you wonder about ways to improve the explanation results. Try to adjust the interpretation by modifying the hyperparameters of LIME.\footnote{If you cannot find hyperparameter configurations for which you get the desired result, you may change the model as well (i.e. reduce the number of estimators or the maximum tree depth).}\\
    \\
\end{enumerate}

Congratulations! E-Corp investor Eter Iehl himself called into your special bonus incentive holiday event\footnote{in the seasteading \textit{Ocean Freedom Nation} in Brazil} to give you the \textit{E-Corp ethical AI award} for tackling unfairness in AI. Unfortunately, just a few days later your holiday is interrupted by an unpleasant report in MIT Tech Review. Tinmit Urbeg publicly accuses E-Corp of cheating by tuning the LIME hyperparameters!\\%Think of ways to adapt the decision boundary such that LIME provides the desired results despite choosing a larger neighborhood.
Eter Iehl is super mad and you have to end the holiday. Sad! But then your supervisor has an idea. She once heard that SHAP relies on unrealistic artificial datapoints...
\begin{enumerate}[resume]
    \item  Exploit the extrapolation to adjust the SHAP interpretation such that skin color and beard are considered irrelevant. \textit{Hint: It is sufficient to sketch an approach with pen and paper.}
    \item Can you think of further ways to "improve" the interpretation?
\end{enumerate}
}
