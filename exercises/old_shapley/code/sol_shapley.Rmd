---
title: "Exercise Shapley"
output: html_document
---
# Libraries
```{r}
library(sets)
library(dplyr)
library(randomForest)
```

# Exercise 1: The Shapely Value 
## Defintion of useful functions
```{r}
### Define the payoff function.
payoff_func <- function(coalition) {
  ### Define boolean variables that indicate whether Timnit, Margret, Samy, Jeff and Larry are in the set or not.
  t <- 't' %in% coalition
  s <- 's' %in% coalition
  m <- 'm' %in% coalition
  j <- 'j' %in% coalition
  l <- 'l' %in% coalition
  
  ### Definition of the overall performance as given in the task.
  10*t + 10*m + 2*j + 20*(t & m) + 20*(t & m & s) - 30*((t | m | s) & j)
}

### Define a payoff difference function (which will be useful for several subtasks. The payoff argument will be helpful for checking the additivity property in task 1c)).
payoff_diff <- function(member, coalition, payoff=payoff_func) {
  payoff(c(member, coalition)) - payoff(coalition)
}

### Define a function that calculates the payoff differences given a list of coalitions (which will be useful for several subtasks. The payoff argument will be helpful for checking the additivity property in task 1c)).
payoff_diff_list <- function(member, coalitions, payoff=payoff_func) {
  sapply(1:length(coalitions), function(i) payoff_diff(member, coalitions[[i]], payoff))
}

### Define a function that returns all Shapley values for a given population (which will be useful for several subtasks. The payoff argument will be helpful for checking the additivity property in task 1c))
all_shapley_values <- function(population, payoff=payoff_func) {
  sapply(1:length(population), function(i) shapley(population[i], population, payoff))
}

### Define a preprocessing function which gives us a list of all possible coalitions (represented as sets) without the member player.
all_coalitions_without_members <- function(members, population) {
  ### Get all players except the member players.
  population_without_members <- setdiff(population, members)
  
  ### Use set_power function to get all sets of players without the member players. 
  all_sets_without_members <- set_power(population_without_members)
  
  ### Convert them to a list for further processing.
  as.list(all_sets_without_members)
}
```

## 1a)
```{r}
### Calculate the Shapley value given a player and the set of all players (The payoff argument will be helpful for checking the additivity property in task 1c)).
shapley <- function(member, population, payoff=payoff_func) {
  all_coalitions_without_member <- all_coalitions_without_members(member, population)
  
  ### Calculate the Shapley value according to the formula given in the lecture or in chapter 9.5.3.1 of Christoph Molnar´s book Interpretable Machine Learning (https://christophm.github.io/interpretable-ml-book/shapley.html#the-shapley-value-in-detail).
  #### Compute the payoff differences with and without the member player for a coalitions at once.
  payoff_diffs <- payoff_diff_list(member, all_coalitions_without_member, payoff)
  
  #### Calculate the weights which are the combinatorical number of occurrences of each set.
  p <- length(population)
  weights <- sapply(1:length(all_coalitions_without_member), function(i) {
    cardinality_coalition <- length(all_coalitions_without_member[[i]])
    factorial(cardinality_coalition) * factorial(p - cardinality_coalition - 1) / factorial(p)
  })
  
  #### The Shapley value now is the weighted sum of the differences.
  sum(weights * payoff_diffs)
}
```

```{r}
### Show the result.
member <- 't'
population <- c('t', 'm', 's', 'j', 'l')
shapley_result <- shapley(member, population)
print(shapley_result)
```

## 1b)
```{r}
### Calculate the permutation based approximation of the Shapley value with num_iter iterations.
shapley_perm <- function(member, population, num_iter=10) {
  ### Sample num_iter permutations from the population (columns are the permutations).
  perms <- replicate(num_iter, sample(population))
  
  ### Find the index of the member player for every permutation (so every column, that´s what the 2 is indicating).
  member_idxs <- apply(perms, 2, function(x) match(member, x))
  
  ### Get the coalition for each permutation (which are just all the players with an index lower than the member player).
  ### They are now saved in a list with the length being the number of iterations.
  coalitions <- lapply(1:num_iter, function(i) perms[1:member_idxs[i] - 1, i])
  
  ### Estimate the Shapley value according to the formula given in the lecture or in chapter 9.5.3.3 of Christoph Molnar´s book Interpretable Machine Learning (https://christophm.github.io/interpretable-ml-book/shapley.html#the-shapley-value-in-detail).
  ### Basically this is just taking the arithmetic mean of the differences of the payoffs of the coalitions with our member player and without. 
  differences <- payoff_diff_list(member, coalitions)
  mean(differences)
}
```

```{r}
### Show the result.
member <- 't'
population <- c('t', 'm', 's', 'j', 'l')
shapley_perm_result <- shapley_perm(member, population, 100000) ### This takes a few seconds.
print(shapley_perm_result)
### A pretty good estimate compared to the result from task a).
```

## 1c)
### Symmetry Check
```{r}
### Check the symmetry property of the Shapley value as defined in the lecture or in chapter 9.5.3.1 of Christoph Molnar´s book Interpretable Machine Learning (https://christophm.github.io/interpretable-ml-book/shapley.html#the-shapley-value-in-detail).
symmetry_check <- function(j, k, population) {
  all_coalitions_without_candidates <- all_coalitions_without_members(c(j, k), population)
  
  ### Calculate the payoff differences for all possible coalitions including j (but excluding k) and for all possible coalitions including k (but excluding j).
  payoff_diff_j <- payoff_diff_list(j, all_coalitions_without_candidates)
  payoff_diff_k <- payoff_diff_list(k, all_coalitions_without_candidates)
  
  ### This logical statement now checks two things:
  ### 1. If the condition is violated.
  ### 2. If the Shapley values are identical.
  ### If the condition is violated the symmetry property holds because of the implication "condition => Shapley values identical" which does not give us any information whether the Shapley values are identical in this case (because from FALSE one can not imply anything).
  ### On the other hand, when the condition is met then the Shapley values have to be identical. This is ensured because in this case the condition is not violated meaning that the left hand side of the OR is FALSE. Therefore the right hand side has to hold which checks whether the Shapley values are identical.
  all(any(payoff_diff_j != payoff_diff_k) | shapley(j, population) == shapley(k, population))
}
```

```{r}
### Check the symmetry property for all possible combinations of two players.
#### All combinations of two players.
all_combinations_two_players <- as.list(set_combn(population, m = 2))
#### The results of the application of the individual symmetry checks.
symmetry_check_all_combinations <- sapply(1:length(all_combinations_two_players), function(i) symmetry_check(as.list(all_combinations_two_players[[i]])[1], as.list(all_combinations_two_players[[i]])[2], population))
#### The combined result.
print(all(symmetry_check_all_combinations))
### Seems to work for our toy example.
```

### Dummy Property Check
```{r}
### Check the dummy property of the Shapley value as defined in the lecture or in chapter 9.5.3.1 of Christoph Molnar´s book Interpretable Machine Learning (https://christophm.github.io/interpretable-ml-book/shapley.html#the-shapley-value-in-detail).
dummy_check <- function(j, population) {
  all_coalitions_without_candidate <- all_coalitions_without_members(j, population)
  
  ### Calculate the payoff differences for all possible coalitions including j (but excluding k) and for all possible coalitions including k (but excluding j).
  payoff_diff_j <- payoff_diff_list(j, all_coalitions_without_candidate)
  
  ### This logical statement now checks two things:
  ### 1. If the condition is violated.
  ### 2. If the Shapley value is 0.
  ### If the condition is violated the dummy property holds because of the implication "condition => Shapley value is 0" which does not give us any information whether the Shapley value is 0 in this case (because from FALSE one can not imply anything).
  ### On the other hand, when the condition is met then the Shapley value has to be 0. This is ensured because in this case the condition is not violated meaning that the left hand side of the OR is FALSE. Therefore the right hand side has to hold which checks whether the Shapley value is 0.
  all(any(payoff_diff_j != 0) | shapley(j, population) == 0)
}
```

```{r}
### Check the dummy property for all possible players.
#### The results of the application of the individual dummy property checks.
dummy_check_all_players <- sapply(1:length(population), function(i) dummy_check(population[i], population))
#### The combined result.
print(all(dummy_check_all_players))
### Seems to work for our toy example.
```

### Additivity Check 
```{r}
### Check the additivity property of the Shapley value as defined in the lecture or in chapter 9.5.3.1 of Christoph Molnar´s book Interpretable Machine Learning (https://christophm.github.io/interpretable-ml-book/shapley.html#the-shapley-value-in-detail).
### Here we assume that the user is giving us two payoff functions that sum up to the original payoff function.
additivity_check <- function(population, payoff_func_1, payoff_func_2) {
  ### Define the combined payoff function.
  payoff_func_1_and_2 <- function(x) payoff_func_1(x) + payoff_func_2(x)
  
  ### Get all the Shapley values when using payoff_func_1 and when using payoff_func_2.
  all_shapley_values_payoff_func_1 <- all_shapley_values(population, payoff_func_1)
  all_shapley_values_payoff_func_2 <- all_shapley_values(population, payoff_func_2)
  
  ### Get all the Shapley values when using the combined payoff function.
  all_shapley_values_payoff_func_1_and_2 <- all_shapley_values(population, payoff_func_1_and_2)
  
  ### Check if the combined Shapley value equals the sum of the Shapley values for every member of the population (rounding is necessary here since the values can differ because of numerical instabilities during computation).
  all(round(all_shapley_values_payoff_func_1_and_2, 5) == round(all_shapley_values_payoff_func_1 + all_shapley_values_payoff_func_2, 5))
}
```

```{r}
### Define a new payoff function (which just consists of the first three summands of the original payoff function).
payoff_func_1 <- function(coalition) {
  ### Define boolean variables that indicate whether Timnit, Margret, Samy, Jeff and Larry are in the set or not.
  t <- 't' %in% coalition
  s <- 's' %in% coalition
  m <- 'm' %in% coalition
  j <- 'j' %in% coalition
  l <- 'l' %in% coalition
  
  ### Definition of the overall performance.
  10*t + 10*m + 2*j
}

### Define the second payoff function accordingly (which hence consists of the second three summands of the original payoff function).
payoff_func_2 <- function(coalition) {
  ### Define boolean variables that indicate whether Timnit, Margret, Samy, Jeff and Larry are in the set or not.
  t <- 't' %in% coalition
  s <- 's' %in% coalition
  m <- 'm' %in% coalition
  j <- 'j' %in% coalition
  l <- 'l' %in% coalition
  
  ### Definition of the overall performance.
  20*(t & m) + 20*(t & m & s) - 30*((t | m | s) & j)
}

### Check the additivity property (at least for the above decomposition of the original payoff function. Of course others are possible). 
additivity_check_result <- additivity_check(population, payoff_func_1, payoff_func_2)
### Show the result.
print(additivity_check_result)
### Seems to work for our toy example.
```

### Efficiency Check 
```{r}
### Check the efficiency property of the Shapley value as defined in the lecture or in chapter 9.5.3.1 of Christoph Molnar´s book Interpretable Machine Learning (https://christophm.github.io/interpretable-ml-book/shapley.html#the-shapley-value-in-detail).
efficiency_check <- function(population) {
  ### The left hand side gives us the total payoff of the population. On the right hand side we sum over the Shapley values of each individual player. For the efficiency property to hold these must be equal.
  payoff_func(population) == sum(all_shapley_values(population))
}
```

```{r}
### Check the efficiency property for the whole population.
#### The result of the application of the efficiency property check for the population.
efficiency_check_result <- efficiency_check(population)
#### Show the result.
print(efficiency_check_result)
### Seems to work for our toy example.
```

# Exercise 2: SHAP
## 2a)
```{r}
library(ranger)

# Read the dataset. 
df <- read.csv(file = "fifa.csv")

# Change the target value to be used as factors for random forest later. 
df$Man.of.the.Match <- ifelse(df$Man.of.the.Match=="Yes",TRUE,FALSE)

# Delete all columns with characters.
df <- df[, !sapply(df, is.character)]

# Delete all columns with NA values.
df <- df[ , apply(df, 2, function(x) !any(is.na(x)))]

# Split the dataset to 70% train data and 30% test data.
set.seed(100)
train = sample(nrow(df), 0.7 * nrow(df), replace = FALSE)
trainData = df[train,]
testData = df[-train,]

# Get X_train, X_test, y_train, y_test for later use.
# Delete all columns with chatacters
X_train <- trainData[,-which(names(trainData) == "Man.of.the.Match")]
X_test <- testData[,-which(names(testData) == "Man.of.the.Match")]
y_train <- factor(trainData[, which(names(trainData) == "Man.of.the.Match")])
y_test <- factor(testData[, which(names(testData) == "Man.of.the.Match")])

# Implement Random Forest Classifier.
set.seed(120)
classifier_RF = ranger(Man.of.the.Match ~ ., trainData)
classifier_RF
```

## 2b) 
```{r}
m_vfunc = function(J, obs, X, model, nr_samples = 10) {
  remainder = setdiff(names(X), J)
  X_tmp <- sample_n(X, nr_samples, replace=TRUE)
  obs_df = obs[rep(1, nr_samples), ]
  X_tmp[, J] = obs[, J]
  pred = predict(model, X_tmp)$predictions
  return(mean(pred))
}

m_vfunc(names(X_train)[1:3], X_test[1,], X_train, classifier_RF, nr_samples=1000)
```

## 2c)
```{r}
sample_mask = function(nrow, ncol) {
  mask_flat = rbinom(nrow*ncol, 1, 0.5)
  mask = matrix(unlist(mask_flat), nrow=nrow, ncol=ncol)
  return(mask)
}

shap_weights = function(mask) {
  p = ncol(mask)
  zs = rowSums(mask)
  nominator = (p - 1)
  denominator = choose(p, zs) * zs * (p - zs)
  return(nominator / denominator)
}

shap_data = function(obs, X, nr_samples, mask) {
  df_obs = obs[rep(1, nr_samples),]
  df_background = sample_n(X, nr_samples, replace=TRUE)
  for (ii in seq(nrow(mask))) {
    for (jj in seq(ncol(mask))) {
      if (mask[ii, jj]) {
        df_background[ii, jj] = df_obs[ii, jj]
      }
    }
  }
  return(df_background)
}

kernel_shap = function(obs, X, nr_samples, model) {
  mask = sample_mask(nr_samples, ncol(X))
  df = shap_data(obs, X, nr_samples, mask)
  weights = shap_weights(mask)
  pred = predict(model, df)$predictions
  
  df_shap = as.data.frame(mask)
  names(df_shap) = names(X)
  df_shap$pred = pred
  
  # since we are in a binary classification scenario we use logreg
  wls_model = glm(pred ~ ., family=binomial, data=df_shap, weights=weights)
  shap_vals = wls_model$coefficients
  return(shap_vals)
}


```

## 2d) 
```{r}
# predictor = Predictor$new(classifier_RF, data=X_train, y=y_train)
# shapley = Shapley$new(predictor, x.interest=X_test[1,])
# shapley$plot()

obs = X_test[1,]
shap_vals = kernel_shap(obs, X_train, 1000, classifier_RF)
```

## 2e) 

Under the most current R version, treeshap does not work. You can either resort to python or downgrade to older versions of R.

SHAP values are expensive to compute. TreeSHAP offers a more efficient implementation that exploits the structure of tree-based models. Advanced knowledge: A further advantage of TreeSHAP is that it resamples the variables such that the joint distribution is preserved.
```{r}
# devtools::install_github('ModelOriented/treeshap')
library(treeshap)
unified_RF <- ranger.unify(classifier_RF,X_train)
explainer = treeshap(unified_RF, X_test)
plot_contribution(explainer, obs=1)
```
# Exercise 3: LIME
## 3a)
```{r}
# devtools::install_github("ModelOriented/DALEX")
# devtools::install_github("ModelOriented/DALEXtra")
library("DALEX")
rf_model = randomForest(Man.of.the.Match ~ ., trainData)

model_ex <- DALEX::explain(model = rf_model,  
                           data = X_train,
                           y = y_train, 
                           label = "Random Forest")


library("DALEXtra")
library("iml")
model_type.dalex_explainer <- DALEXtra::model_type.dalex_explainer
predict_model.dalex_explainer <- DALEXtra::predict_model.dalex_explainer

iml_obs <- predict_surrogate(explainer = model_ex, 
                  new_observation = X_test[1,],
                  type = "lime")

plot(iml_obs)
```
## 3b)
```{r}
iml_obs <- predict_surrogate(explainer = model_ex, 
                  new_observation = X_test[1,],
                  type = "lime",
                  kernel_width=10)

plot(iml_obs)

iml_obs <- predict_surrogate(explainer = model_ex, 
                  new_observation = X_test[1,],
                  type = "lime",
                  kernel_width=0.001)

plot(iml_obs)
```
## 3c)
Both SHAP and Lime rely on a linear model approximation of the model. For Lime, the normal feature values are used, for SHAP a transformed distribution indicating coalition membership for a sample is relied upon. Lime weights the different samples according to their distance to the observation of interest. In contrast, SHAP weights them according to the Shapley kernel weights (which simulate sampling random permutations).


