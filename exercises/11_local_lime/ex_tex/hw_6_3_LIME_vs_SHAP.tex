\aufgabe{LIME and SHAP}{
In this exercise, we want to compare LIME to SHAP (or Shapley values), since both are local explanation methods.
In contrast to SHAP, LIME is based on locally approximating the decision function using a linear model, whose coefficients can then be interpreted as usual.
But like SHAP, LIME is an additive attribution technique.
\begin{enumerate}
    \item
    Apply a LIME implementation to the FIFA dataset from Exercise 1 on sheet 9.
    You can either use your own implementation from Exercise~\ref{ex:LIME_implementation}, or use the available imlementations in \href{https://github.com/marcotcr/lime}{python} or \href{https://cran.r-project.org/web/packages/lime/index.html}{R}.
    \item
    Try different hyperparameter configurations for LIME (for instance, modify the kernel width).
    How does that influence the result?
    \item
    Compare the results from LIME to those from SHAP from Exercise 1 on sheet 9.
    In what way are LIME and SHAP similar? How do the methods differ?
\end{enumerate}
}
