---
title: "Exercise Sheet 9: SHAP"
output:
  pdf_document: default
  html_document: default
---

# Exercise 1: SHAP

```{r}
### For modelling a random forest we use the ranger package.
library(ranger)

set.seed(123456)
```

## a)
```{r}
### Read the dataset via the read.csv()-function.
df <- read.csv(file = "fifa.csv")

### Now transform the character variable Man.of.the.Match which only contains the  
  ### values "Yes" and "No" into a logical variable with values TRUE (former "Yes")
  ### and FALSE (former "No"). Note that this step has to be done before deleting
  ### all character variables because else we would remove our target variable as well.
df$Man.of.the.Match <- ifelse(df$Man.of.the.Match == "Yes", TRUE, FALSE)

### Remove all variables of type character.
df <- df[, !sapply(df, is.character)]

### Here we delete all columns containing at least one NA value.
df <- df[ , apply(df, 2, function(x) !any(is.na(x)))]

### Classical training and testing split.
train_idx <- sample(nrow(df), 0.7 * nrow(df))
training_data <- df[train_idx, ]
test_data <- df[-train_idx, ]

### Split of our training and testing datasets into features and  
  ### target which will be used later on.
X_train <- training_data[ , -which(names(training_data) == "Man.of.the.Match")]
X_test <- test_data[ , -which(names(test_data) == "Man.of.the.Match")]
y_train <- factor(training_data[ , which(names(training_data) == "Man.of.the.Match")])
y_test <- factor(test_data[ , which(names(test_data) == "Man.of.the.Match")])

### Modelling a random forest using the ranger package. Other packages are possible  
  ### as well.
classifier_RF <- ranger(Man.of.the.Match ~ ., training_data)
classifier_RF

### Example instance
predict(classifier_RF, X_test[1:5,])$predictions

### As a classifier, this model of course produces probabilities as outputs, which are then
### transformed into a binary prediction. This is not very well suited for Shapley values,
### since they basically require a numerical or continuous target, in particular for the
### efficiency axiom to hold up. We will nevertheless work with the binary predictions
### (interpreted numerically as 0 or 1) in this exercise, but since the Shapley or SHAP values
### are both obtained through averaging, they then still always represent probabilities
### or relative frequencies.
```

## b) 
```{r}
### Computing the marginal sampling based SHAP value function as defined in the  
  ### lecture or in chapter 18 of Christoph Molnar's book Interpretable Machine
  ### Learning (https://christophm.github.io/interpretable-ml-book/shap.html#kernelshap).
marginal_vfunc <- function(S, observation, X, model, nr_samples = 100) {
  ### Get nr_samples random observations from the given dataset.
  X_tmp <- X[sample(nrow(X), nr_samples, replace = TRUE), ]
  
  ### Now replace the features given in S for our samples by the values of the  
  ### features in S given by the observation.
  X_tmp[ , S] <- observation[ , S]
  
  ### Use the model to predict the target and take the arithmetic mean of the  
  ### predictions.
  mean(predict(model, X_tmp)$predictions)
}

marginal_vfunc(names(X_train)[1:3], X_test[1, ], X_train, classifier_RF, nr_samples = 1000)
marginal_vfunc(names(X_train)[1], X_test[1, ], X_train, classifier_RF, nr_samples = 1000)
marginal_vfunc(names(X_train)[1:2], X_test[1, ], X_train, classifier_RF, nr_samples = 1000)
marginal_vfunc(names(X_train)[1:2], X_test[2, ], X_train, classifier_RF, nr_samples = 1000)
```

## c)
Necessary functions from the last exercise (copied):
```{r}
library(sets)

### Define the payoff function.
payoff <- function(coalition) {
  ### Not necessary in this exercise
  NULL
}

### Define a payoff difference function (which will be useful for several
  ### subtasks. The v_function argument will be helpful for checking the additivity
  ### property in task 1c).
payoff_diff <- function(member, coalition, v_function=payoff) {
  v_function(c(member, coalition)) - v_function(coalition)
}

### Define a function that calculates the payoff differences given a list of
  ### coalitions (which will be useful for several subtasks. The v_function argument
  ### will be helpful for checking the additivity property in task 1c)).
payoff_diff_list <- function(member, coalitions, v_function=payoff) {
  sapply(1:length(coalitions), function(i) payoff_diff(member, coalitions[[i]], v_function))
}

### Define a function that returns all Shapley values for a given population
  ### (which will be useful for several subtasks. The v_function argument will be
  ### helpful for checking the additivity property in task 1c))
all_shapley_values <- function(population, shapley_fct, v_function=payoff) {
  sapply(1:length(population), function(i) shapley_fct(population[i], population, v_function))
}

shapley_test <- function(population, shapley_fct, v_function=payoff) {
  shapley_values <- all_shapley_values(population, shapley_fct, v_function)
  print(shapley_values)
  sum_ <- sum(shapley_values)
  print(sum_)
  print(v_function(population))
  print(sum_ == v_function(population))
}

### Calculate the permutation based approximation of the Shapley value with  
  ### num_iter iterations.
shapley_perm_approx <- function(member, population, v_function=payoff, num_iter=100) {
  ### Sample num_iter permutations from the population (the single columns are the permutations).
  perms <- replicate(num_iter, sample(population))
  
  ### Find the index of the member player for every permutation (so in every column,
  ### thatÂ´s what the 2 is indicating).
  member_idxs <- apply(perms, 2, function(x) match(member, x))
  
  ### Get the coalition for each permutation (which are just all the players with  
  ### an index lower than the member player).
  ### They are now saved in a list with the length being the number of iterations.
  coalitions <- lapply(1:num_iter, function(i) perms[1:member_idxs[i] - 1, i])
  
  ### Estimate the Shapley value according to the algorithm given in the lecture or
  ### in chapter 17 of Christoph Molnar's book Interpretable Machine Learning
  ### (https://christophm.github.io/interpretable-ml-book/shapley.html#estimating-shapley-values).
  ### This is just the arithmetic mean of the payoff differences 
  ### over all sampled coalitions, same as for the exact order definition.
  differences <- payoff_diff_list(member, coalitions,v_function)
  mean(differences)
}
```

```{r}
### Testing the approximation algorithm
model_specific_marginal_vfunc <- function (coalition) {
  marginal_vfunc(coalition, X_test[1, ], X_train, classifier_RF, nr_samples = 100)
}
print(shapley_perm_approx(names(X_test)[3], names(X_test),
                          v_function = model_specific_marginal_vfunc))
print(shapley_test(names(X_test), shapley_perm_approx, v_function = model_specific_marginal_vfunc))
### Here we see exactly the problem mentioned earlier: The Shapley value (or the
### approximated Shapley value) represent a probability, but could be any value,
### whereas the prediction of the model is either 0 and 1, and efficiency does not
### hold in this specific situation anymore.
```

## d)
```{r}
### A function to sample for every entry in our data whether to include it or not.
sample_mask <- function(nrow, ncol) {
  ### Sample nrow * ncol times from a fair binomial distribution and arrange the  
  ### result in an accordingly shaped matrix.
  matrix(rbinom(nrow * ncol, 1, 0.5), nrow = nrow)
}

### A function to return the weights for our randomly drawn mask. The formula can  
  ### be found in chapter 18 of Christoph Molnar's book Interpretable Machine
  ### Learning (https://christophm.github.io/interpretable-ml-book/shap.html#kernelshap),  
  ### it's the defintion of pi_x(|z'|) where |z'| is the 1-norm (so in our case just
  ### the number of included features given by a 1 in the mask).
shap_weights <- function(mask) {
  ### The number of features.
  p <- ncol(mask)
  
  ### The number of included features, |z'|.
  z_prime_abs <- rowSums(mask)
  
  ### The application of the formula.
  (p - 1) / (choose(p, z_prime_abs) * z_prime_abs * (p - z_prime_abs))
}

### A function to create the dataset generated during the SHAP calculations. This  
  ### are just n_samples of the original observations
### where the positions in the mask indicate where we replace the original  
  ### values with the ones of the given observation obs.
replace_dataset <- function(obs, X, n_samples, mask) {
  ### Get n_samples random observations from the given dataset.
  X_new <- X[sample(nrow(X), n_samples, replace = TRUE), ]
  
  ### Blow up the size of the given observation to be compatible to our sampled  
  ### dataset.
  obs_rep <- obs[rep(1, n_samples), ]
  
  ### Now apply the mask. At the positions where the mask is 0 we just get the first
  ### term. At the positions where the mask is 1 we basically subtract X_sample  
  ### from X_sample and what is left is the respective entry in df_obs. So at  
  ### these positions we effectively replace the original entries by the ones in df_obs.
  X_sample <- X_new - mask * (obs_rep - X_new)
  
  ### Return the result.
  X_sample
}

### Now, we put things together and implement the sampling based KernelSHAP funtion.
kernel_shap <- function(obs, X, n_samples, model) {
  ### Get the SHAP weights and the predictions of a random sample of the given data.
  mask <- sample_mask(n_samples, ncol(X))
  df <- replace_dataset(obs, X, n_samples, mask)
  weights <- shap_weights(mask)
  pred <- predict(model, df)$predictions
  
  ### Now save the mask as well as the respective predictions.
  df_shap <- as.data.frame(mask)
  names(df_shap) <- names(X)
  df_shap$pred <- pred
  
  ### Fit a weighted linear model using the above calculated weights. Since we  
  ### are in a binary setting, we perform logistic regression.
  wls_model <- glm(pred ~ ., family = binomial, data = df_shap, weights = weights)
  wls_model$coefficients
}
```

## e)
```{r}
### Calculate the KernelSHAP values for the first instance of the test set.
obs <- X_test[1, ]
shap_vals <- kernel_shap(obs, X_train, 1000, classifier_RF)
shap_vals
```

