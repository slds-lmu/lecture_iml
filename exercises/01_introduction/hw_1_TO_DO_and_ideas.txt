

Explicitly derive correlation measure or \(R^2\) for non-linear models / generalizations of \(R^2\)

    Or generalization of Pearson coefficient for non-linear relationships ?  (see also in-class quiz task)



Explicit calculating example for mutual information:

    - for independent variables
    - for dependent variables with correlation coefficient \(\neq 0\)
    - dependent variables with 0 correlation (because not linearly dependent)    DONE, HA 1 c)
    - MI also for categorical variables





- review of basics on (in-)dependence, conditional probabilities / expectations, joint / marginal distributions   (see basics stat / probability course)



@ Motivation & Goals of IML:
- Train a (standard, easy) ML model
    What seems strange to you? What could it have learned wrongly?
    What do you want to know about the model?
    [See also in-class Discussion Question]
- [Real-Life / Applcation Scenario] A customer or the like has a standard request towards an ML engineer => What do you need to know about the model for that? Which IML method ( which dimension) do you need?
    - Or given 2 models, one case where the error / bug can easily be detected & solved (without heavy IML machinery), and one case in which it can not





Interactions, for HA 3:

- Add easy example without interaction
- Some complicated function using sine and cosine, which actually exhibits no interactions (which can only be seen after applying Angle sum identities (Additionstheoreme))
- Add a visualization of the functions, so that students can give a guess before calculating and check whether or not they are able to "detect" interactions based on visualization only

- Problem: A decision tree itself is not differentiable, so this definition of interactions does not apply, whereas the same definition using empirical dsitribution (and finite differences) could be applied !
    -> Exercise on that? Have students figure out definition with finite differences themselves ?

Bonus:
Develop oneself Definition of interactions for categorical / discrete features using finite differences  (analogously with expectation of square of finite differences)





Programming-HA for showing / visualizing: Correlated features cause interactions in ML model, even if no interactions are actually present
    -> How does the DGP need to look like?

    - E.g.: Decision tree on two features, and true function only depends on one of them
        If both features independent, tree will only consider correct feature
        If features are strongly correlated, tree will learn interaction
        => Only looking at ML model makes the impression as if interactions were present

        see also homework exercise 2-4

    Or: DGP has the functional form x_1^2 + x_2  &  one learns a quadratic regression
        If x_1 and x_2 (or other features) are independent, correct form will be learned
        If they are correlated, also "x_1*x_2" term will be learned (incorrectly)

    Or: functional form is e^{x_1} + x_2, but also e^{x_1 + x_2} will be learned in case of correlation





- Reproduce "Interpretability vs Performance" tradeoff curve from the lecture
    - Train several models of different complexity on one dataset
        - e.g. Decision Trees or Ensembles with different depths => the deeper the tree / ensemble, the more complex
            see also homework exercise 2-4
            
        - e.g. reuse a Tuning exercise from I2ML ?
            Exercise on benchmarking (with random forests) from AppML
            Exercise 8-2 from I2ML (training a DT with CART and different max_depth)
            Exercise 9 from I2ML on RFs  ????
            Exercise 12 on nested resampling from I2ML: Compare all models in this exercise. Although their complexity / performance is all very similar ??







