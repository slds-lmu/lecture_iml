\textbf{Solution Quiz:}\\\noindent
\medskip

\begin{enumerate}
%    \item What is the prediction target in contrast to the prediction?
%    \begin{itemize}
%    	\item[$\Rightarrow$] The prediction target is the hole set of possible targets whereas the prediction is the concrete output after applying a prediction function.
%    \end{itemize}
%    \item What is the model's mechanism in contrast to the data generating process (DGP)?
%    \begin{itemize}
%    	\item[$\Rightarrow$]  The DGP is the true underlying process generating the data. The model is estimated by optimizing the prediction performance, i.e. the model's mechanism tries to be a copy of the DGP but this mostly is not possible.
%    \end{itemize}
	\item What is motivating idea behind Shapley values? 
	\begin{itemize}
		\item[$\Rightarrow$] fairly divide the total achievable payout $v(P)$ among the players according to a playerâ€™s individual contribution
	\end{itemize}
	\item How is the Shapley idea realized / implemented in IML?
	\begin{itemize}
		\item[$\Rightarrow$] players = features, \\game = prediction for a single observation, \\Shapley value = individual payout per player (feature)
		\item[$\Rightarrow$] Calculate marginal contribution for adding a feature to every possible coalition and average the resulting values
	\end{itemize}
	\item What is a practical problem of Shapley values and how is it solved?
	\begin{itemize}
		\item[$\Rightarrow$] Computation for high dimensional feature spaces (large power set $P$, many marginal predictions)
		\item[$\Rightarrow$] Solution: sampling (The more coalitions are sampled, the exacter the computation will be but also more computationally expensive)
	\end{itemize}
    \item Yes or No: Shapley values and SHAP values are different names for the same concept.
    \begin{itemize}
    	\item[$\Rightarrow$] Not directly as for calculating SHAP values a (more efficient) estimation procedure is used. Still, all SHAP values are Shapley values (but not all Shapley values are SHAP values). The estimated SHAP and Shapley values can be different as Shapley values are often approximated by different procedures.
    \end{itemize}
    \item What are SHAP value functions $v$ in contrast to SHAP values $\phi$?
    \begin{itemize}
    	\item[$\Rightarrow$] SHAP value function: a function assigning a value to a coalition
    	\item[$\Rightarrow$] SHAP values: Contribution of a feature to a prediction
    \end{itemize}
%    \item What is the difference between marginal and conditional SHAP?
%    \begin{itemize}
%    	\item[$\Rightarrow$] The features that are not part of the coalition or the feature of interest are sampled from the marginal or the conditional distribution, respectively.
%    \end{itemize}
%    \item What is the motivation of LIME?
%    \begin{itemize}
%    	\item[$\Rightarrow$] Interpret a model locally by fitting a simple model (independent of the complexity of the global ML model). $\rightarrow$ local surrogate model
%    \end{itemize}
%    \item Both SHAP and LIME can be seen as local linear approximations. Name differences between SHAP and LIME.
%    \begin{itemize}
%    	\item[$\Rightarrow$] 
%    \end{itemize}
%    \item Name hyperparameters for LIME. What do they steer?
%    \begin{itemize}
%    	\item[$\Rightarrow$] 
%    \end{itemize}
\end{enumerate}
