

- Finish and upload solutions for exercises on GAM and EBM !

- add pseudocode in the latex solutions for all implementation exercises



GAM

- Exercise to calculate / implement GAM once
    -> done by exercise 3-2 ? Or more complex one / more complex dataset wanted?

- Exercise 3-2 for Interactions in GAMs
    still TO DO: Visualize all the different models (the LMs, the GAMs (single components), and the EBMs (single components))
        evtl. also give the DGP formula, so that another task can be to prove via hand that there is actually an interaction ??  Or this maybe for a little more complex example ? (see also ideas for exercise 1-3)
    TO DO: Tailor single tasks more to single data sets

    Maybe extract the visualization to an extra exercise before ? Or extra sub exercise?



Boosting

@ Exercise 3-1: little more complex (more features to interpret)



RPF
- s. RPF preparation exercise inside exercise 2-4 (CART implementation)

- bigger  / realistic comparison of EBM and  / or  RPF to more powerful models (RFs & XGBoost)
    => R implementation for RPF exists, but need to make it work first ??
    => For EBM, only python implementation in interpret_ML paket from Microsoft exists => Would need an R wrapper if to by used inside mlr3 (for efficiently integrating into bigger benchmarks / pipelines)
    => very big effort  ?

    - or implement or run different variants (of RPF or of RFs or of XGBoost), i.p. variants with different depths    =>   see interaction-vs-performance tradeoff exercise in Ch. 1

    
EBM:
- implement EBM from scratch ?  "which is not hard"  ?
    FAST Algo is important part of EBM
    => task to calculate this manually at least once
    => Implement from scratch ?  I.e. without all the optimizations / efficiency
        Or implement only parts, structure / skeleton of implementation is given ?

- Given: An EBM with only 3 (or 5) interaction terms on the bike sharing dataset, and visualizations for all components.
    Task: Interpret the EBM  &  analyse the data

- Train & Interpret an EBM on a (more complex) dataset, as well as train the other models from this chapter (or results for other models are given), and compare => show that only an EBM yields good results
    Examples from the original paper ?

- different exercise for: visualize all components of an EBM ?





- theoretic / proof exercises from the original papers (EBM / RPF)



- "Interpretability vs Performance" tradeoff exercise from chapter 1
    -> could be done with one of the models in this chapter ???


