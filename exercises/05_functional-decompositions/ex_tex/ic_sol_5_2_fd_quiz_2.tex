\textbf{Solution Quiz:}\\\noindent
\medskip

\begin{enumerate}

    \item
    What are problems of computing and using functional decompositions in practice, and how can one deal with them?
    
    \begin{itemize}
    
        \item 
        Many features / high dimensional function $\implies$ expensive to compute and complicated to understand $\leadsto$ Solution: Sparse decomposition, or only focus on specific interactions of interest, or force decomposition to be sparse by design in interpretable models like EBMs
        \item 
        Only for tabular data, extracting tabular data from raw data, or in general machine learning models for processing raw data, is difficult to analyze
        \item 
        All methods have individual disadvantages, only for the case of independent features does standard fANOVA offer something like an ``all-round solution''.
        
    \end{itemize}
    
    \item 
    What do the vanishing condition and the orthogonality condition intuitively mean?
    
    \begin{itemize}
    
        \textbf{Vanishing condition}: All PD-functions of any components are 0, meaning that all components contain no lower-order interactions, but only the single contribution from the interaction they are representing.
    
        \textbf{Orthogonality condition}: All the components are uncorrelated, meaning that all effects are indeed cleanly separated between the components and that (at least stochastically) there are no mixed effects between components.
    
    \end{itemize}
    
\end{enumerate}