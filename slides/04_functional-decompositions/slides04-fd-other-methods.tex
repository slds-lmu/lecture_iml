\documentclass[11pt,compress,t,notes=noshow, aspectratio=169, xcolor=table]{beamer}

\usepackage{../../style/lmu-lecture}
% Defines macros and environments
\input{../../style/common.tex}
\newcommand{\open}{}
\newcommand{\close}{}

\title{Interpretable Machine Learning}
% \author{LMU}
%\institute{\href{https://compstat-lmu.github.io/lecture_iml/}{compstat-lmu.github.io/lecture\_iml}}
\date{}

\begin{document}

\newcommand{\titlefigure}{figure/open_blackbox}
\newcommand{\learninggoals}{
\item Limitations of classical fANOVA
\item Overcoming these limitations with generalized fANOVA
\item How ALE Plots can be used as another, different approach to obtain functional decompositions
\item Sobol-Hoeffding decomposition ??}

\lecturechapter{Functional Decompositions: Further Methods}
\lecture{Interpretable Machine Learning}

\begin{frame}{Limitations of classical fANOVA}

    [Example going wrong with correlated features]

    \begin{example}

        Again consider

        \begin{equation*}
            \fh(x_1, x_2, x_3) = - 2x_1 - 2\sin(x_3) + |x_1|x_2 + 0.5 x_2 x_3 +1
        \end{equation*}

        and further assume that the following dependency always holds: \(2x_1^2 = x_2\). Then for example the following two decompositions would both "make sense":
        
    \end{example}

    [...]

    
    
\end{frame}

\begin{frame}{Generalized Functional ANOVA}

    \textbf{N.B.:} For dependent inputs, \citebutton{Hooker (2007)}{http://www.tandfonline.com/doi/abs/10.1198/106186007X237892} showed the existence of a unique solution for the components under a ``relaxed vanishing condition'' which leads to a ``hierarchical orthogonality''
    $$\mathbb{E}_{\Xv} (g_{V}(\xv_V) g_{S}(\xv_S)) = 0, \forall V \subset S$$
    $\leadsto$ Only components are orthogonal where features involved in $g_{V}(\xv_V)$ also appear in $g_{S}(\xv_S)$
    %Only components where all features involved in one component $g_{V}(\xv_V)$ also appear in the other component $g_{S}(\xv_S)$ are orthogonal

    \pause

    \textit{[Also talk about constraints corresponding to generalized fANOVA ?]}
    
\end{frame}

\begin{frame}{Generalized fANOVA: Example}

    Example from above ??
    
\end{frame}

\begin{frame}{Revisiting ALE Plots}

    Recap: ALE PLots [...]
    
\end{frame}

\begin{frame}{ALE Decomposition}
    
    ALE Plots also can lead to a full functional decomposition: [...]
    
\end{frame}

\begin{frame}{Sobol-Hoeffding decoomposition}
    
\end{frame}

\begin{frame}{if enough time: Constraints (theory) for these other methods}
    
\end{frame}

\begin{frame}{Conclusion: How useful are functional decompositions?}

    Obwohl fDecompositions eigtl (aus Interpretability-Sicht) die Lösung für alles wären / theoretisch die Endlösung sind, sind alle anderen Methoden trotzdem nötig, weil fDecompositions sehr schwierig \& kompliziert zu berechnen sind
      - Computation time skaliert exponentiell mit der Dimension / Anzahl features  =>  i.a. ist Erzwingen einer sparsen decomposition (s. GAMs / RPFs) die einzige realisitische Möglichkeit \\

    Nevertheless, functional decompositions are a very important interpretability concept, because they explain / are the idea behind many other methods and enable much better understanding of other methods.
    
\end{frame}










\endlecture
\end{document}
