\documentclass[11pt,compress,t,notes=noshow, aspectratio=169, xcolor=table]{beamer}

\usepackage{../../style/lmu-lecture}
% Defines macros and environments
\input{../../style/common.tex}

\title{Interpretable Machine Learning}
% \author{LMU}
%\institute{\href{https://compstat-lmu.github.io/lecture_iml/}{compstat-lmu.github.io/lecture\_iml}}
\date{}


\begin{document}

\newcommand{\titlefigure}{figure_man/bike-sharing03.png}
\newcommand{\learninggoals}{
\item See model predictions as a cooperative game
\item Transfer the Shapley value concept from game theory to machine learning
}

\lecturechapter{Shapley Values for Local Explanations}
\lecture{Interpretable Machine Learning}


\begin{frame}{From Game Theory To Machine Learning}

\begin{figure}
    \centering
    \includegraphics{figure/Shapley_6.png}
\end{figure}

\end{frame}

\begin{frame}{From Game Theory to Machine Learning}
\begin{itemize}[<+->]
    %\itemsep1em
    \item Game: Make prediction $\fh(x_1, x_2, \ldots, x_p)$ for a single observation $\xv$
    \item Players: Features $x_j, j \in \pset$ which cooperate to produce a prediction\\
    $\leadsto$ How can we make a prediction with a subset of features without changing the model?
    \\ 
    $\leadsto$ Partial Dependence (PD) function: $\fh_{S}(\xv_S) := \int_{X_{-S}} \fh(\xv_S, X_{-S})d \P_{X_{-S}}$ (``removing'' by marginalizing over $-S$)
    \item For $S = \emptyset \quad \fh_{S}(\xv_S) = \E_{\xv}(\fh(\xv))$ (average over all possible values of all the features) $\leadsto$ Can't be used as a value function since $v(\emptyset)$ must be $0$ but $\E_{\xv}(\fh(\xv))$ can be  non zero. \\$\leadsto$ Solution: subtract $\E_{\xv}(\fh(\xv))$ from the PD.
    \item We define the value function / payout of coalition $S \subseteq P$ for observation $\xv$:
    $$v(S) =  \fh_{S} (\xv_S) - \E_{\xv}(\fh(\xv)), \text{ where } %\xv_S = \{x_j\}_{j \in S} \text{ and } 
    \fh_S: \Xspace_S \mapsto \Yspace$$
    \centerline{\includegraphics[width=0.5\textwidth, trim=20 0 0 100, clip]{figure_man/shapley_valuefct}}
    \item Marginal contribution: $v(\Scupj) - v(S) =  \fh_{\Scupj} (\xv_{\Scupj}) - \fh_{S} (\xv_{S})$\\
    $\leadsto$ $\E_{\xv}(\fh(\xv))$ cancels out due to the subtraction of value functions
\end{itemize}
\end{frame}
% \begin{frame}{Shapley Values}
%   We can use Shapley values to explain individual predictions $\fh(\xv)$ of a machine learning model $\fh$:
% \begin{itemize}
%   \item Players $\hat{=}$ feature values of $i$-th observation $x_j, j \in \pset$.
%   \item Features cooperate to produce a prediction $\fh(x_1, x_2, \ldots, x_p)$.
%   \item The value function / payout of coalition $S$ for observation $\xv$ is
%     $$v(S) =  \fh_{S} (\xv_S) - \E_{\xv}(\fh(\xv)),$$ 
%     where $\xv_S = \{x_j\}_{j \in S}$ and $\fh_S: \Xspace_S \mapsto \Yspace$.
% \item The marginal prediction $\fh_S$ is defined as $\fh_{S}(\xv_S) := \int_{X_{-S}} \fh(\xv_S, X_{-S})d \P_{X_{-S}}$
% \item We have already seen the marginal prediction in action in the PDP.
% \item The subtraction of $\E_{\xv}(\fh(\xv))$ is necessary so that $v$ is a value function with $v(\emptyset) = 0$.
% \item By using the marginal prediction, we have defined what it means for features to be \enquote{missing} for the prediction: We remove it by integrating over its distribution.
% \end{itemize}
% \begin{center}
% \vspace{-0.3cm}
% \includegraphics[width=0.6\textwidth]{figure_man/shapley_valuefct}
% \end{center}

% \begin{itemize}
%  \item Shapley values tell us what the payout of each feature is, i.e., how each feature contributes to the overall prediction of a specific observation.
%     \item The Shapley value is the average marginal contribution of a feature towards the prediction \textbf{across all possible feature coalitions}.
%     \item The sum of Shapley values over all features yields the difference between the average prediction of all data points (baseline) and the selected individual prediction.
%   \end{itemize}
% \end{frame}

\begin{frame}{Shapley Value - Definition \citebutton{Shapley (1953)}{https://doi.org/10.7249/P0295} \citebutton{Strumbelj et al. (2014)}{https://doi.org/10.1007/s10115-013-0679-x}}
  %Using the order definition, the Shapley value for feature $j$ and a given observation $\xv$ is computed by:
  Shapley value $\phi_j$ of feature $j$ for observation $\xv$ via \textbf{order definition}:

     $$ \phi_j(\xv)  = \frac{1}{|P|!} \sum_{\tau \in \Pi} \underbrace{\fh_{\Stauj}(\xv_{\Stauj}) - \fh_{\Stau}(\xv_{\Stau})}_{\text{marginal contribution of feature $j$}} $$ %S \subseteq P\setminus \{j\}
     
     
\begin{itemize}
    
  \item Interpretation: Feature $x_j$ contributed $\phi_j$ to difference between $\fh(\xv)$ and average prediction\\
  $\leadsto$ Note: Marginal contributions and Shapley values can be negative
  %$x_j$ contributed $\phi_j$ to prediction $\fh(\xv)$ compared to average prediction
  % of Shapley value $\phi_j$ for feature $j$ and observation $\xv$:\\
  %Feature value $x_j$ contributed amount $\phi_j$ to prediction $\fh(\xv)$ compared to the average prediction
   \item For exact computation of $\phi_j(\xv) $, the PD function 
   %$\fh_{S}(\xv_S) =  \frac{1}{n} \sum_{i=1}^n \fh_S^{(i)}(\xv_S) = \frac{1}{n} \sum_{i=1}^n \fh(\xv_S, \xv_{-S}^{(i)})$ 
   $\fh_{S}(\xv_S) = \frac{1}{n} \sum_{i=1}^n \fh(\xv_S, \xv_{-S}^{(i)})$ 
   for any set of features $S$ can be used which yields
   %$$ \phi_j(\xv) = \frac{1}{|P|! \cdot n} \sum_{\tau \in \Pi} \sum_{i = 1}^n \fh_{\Smj}^{(i)}(\xv_{\Smj}) -  \fh_{\Sm }^{(i)}(\xv_{\Sm}) $$
    $$ \phi_j(\xv) = \frac{1}{|P|!} \sum_{\tau \in \Pi} \frac{1}{n} \sum_{i = 1}^n
   \fh(\xv_{\Stauj}, \xv_{\minusStauj}^{(i)}) - \fh(\xv_{\Stau}, \xv_{- \Stau}^{(i)})
   $$
   $\leadsto$ Note: $\fh_S$ marginalizes over all other features $-S$ using all observations $i = 1, \ldots, n$
   
\end{itemize}
\lz
%\tiny
%Shapley, Lloyd S. 1953. $"$A Value for N-Person Games.$"$\\
%\vspace{0.2cm}
%Strumbelj, Erik, Igor Kononenko, Erik Strumbelj, and Igor Kononenko. 2014. $"$Explaining prediction models and individual predictions with feature contributions.$"$

\end{frame}


\begin{frame}{Estimation: A practical problem}
  \begin{itemize}[<+->]
  %\itemsep1em
      \item Exact Shapley value computation is problematic for high-dimensional feature spaces\\
      $\leadsto$ For 10 features, there are already $|P|! = 10! \approx 3.6$ million possible orders of features
      \item Additional problem due to estimation of the marginal prediction $\fh_{\Stau}$: Averaging over the entire data set for each coalition $\Stau$ introduced by $\tau$ can be very expensive for large data sets
      \item Solution to both problems is sampling:
      Instead of averaging over $|P|! \cdot n$ terms, we approximate it using a limited amount of $M$ random samples of $\tau$ to build coalitions $\Stau$
      %We calculate the Shapley value over $M$ samples -- for each sample, we sample one order of features and one data point to replace missing features
      \item $M$ is a tradeoff between accuracy of the Shapley value and computational costs\\
      $\leadsto$ The higher $M$, the closer to the exact Shapley values, but the more costly the computation
      %- the higher $M$, the closer we get to the true Shapley values, but the more costly the computation becomes
  \end{itemize}
\end{frame}

\newcommand{\xk}{\mathbf{x}^{(k)}}

\begin{frame}{Approximation Algorithm \citebutton{Strumbelj et al. (2014)}{https://doi.org/10.1007/s10115-013-0679-x}}
Estimation of $\phi_j$ for observation $\xv$ of model $\fh$ fitted on data $\D$ using sample size $M$:
%\vspace{0.25cm}
  \begin{enumerate}[<+->]
      \item For $m = 1, \ldots, M$ \textbf{do}:
      \begin{enumerate}
        \item Select random order / perm. of feature indices $\tau = (\tau^{(1)}, \ldots, \tau^{(p)}) \in \Pi$
        %\item Select random data point $\xv^{(k)} \in X$.
        %\item Let $\Sm := \Sm$ be the set of features before $j$ of order $\tau$ forming a coalition
        \item Determine coalition $\Sm := \Stau$, i.e., the set of feat. before feat. $j$ in order $\tau$
        \item Select random data point $\mathbf{z}^{(m)} \in \D$%\\
        %$\leadsto$ used to marginalize over
        %\item Order feature values in $\xv$ according to $\tau$: $\xv_{\tau} = (x_{\tau^{(1)}}, \ldots, x_{\tau^{(j)}}, \ldots, x_{\tau^{(p)}})$
        %\item Order feature values in $\mathbf{z}^{(m)}$ according to $\tau$: $\mathbf{z}_{\tau}^{(m)} = (z_{\tau^{(1)}}^{(m)}, \ldots, z_{\tau^{(j)}}^{(m)}, \ldots, z_{\tau^{(p)}}^{(m)})$
        \item Construct two artificial obs. by replacing feature values from $\xv$ with $\mathbf{z}^{(m)}$:
          \begin{itemize}
          \setlength\itemsep{.5em}
            \item % 
            $ \xjp  = (\underbrace{x_{\tau^{(1)}}, \ldots, x_{\tau^{(|\Sm|)}}, x_{j}}_{\xv_{\Smj}}, \underbrace{z_{\tau^{(|\Sm|+2)}}^{(m)} , \ldots, z_{\tau^{(p)}}^{(m)}}_{\mathbf{z}^{(m)}_{\minusSmj}} )$
            takes features $\Smj$ from $\xv$
            %(with value of feature $j$ from $\xv$)
            \item % \xjm =
            $ \xjm = (\underbrace{x_{\tau^{(1)}}, \ldots, x_{\tau^{(|\Sm|)}}}_{\xv_{\Sm}}, \underbrace{z_{j}^{(m)} , z_{\tau^{(|\Sm|+2)}}^{(m)} , \ldots, z_{\tau^{(p)}}^{(m)}}_{\mathbf{z}^{(m)}_{-\Sm}} )$
            takes features $\quad$  $\Sm$ from $\xv$ (takes $\{j\}$ randomly)
            %(without value of feature $j$ from $\xv$)
          \end{itemize}
        \item Compute difference $\phi_j^m = \fh(\xjp) - \fh(\xjm)$ \\
        $\leadsto$ $\fh_{\Sm}(\xv_{\Sm})$ is approximated by $\fh(\xv_{-j}^{(m)})$ and  $\fh_{\Smj}(\xv_{\Smj})$ by  $\fh(\xv_{+j}^{(m)})$ over $M$ iters.
        %$\hat =$ A random sample from the marginal contribution of feature $j$ to coalition $\Sm$
        \end{enumerate}
        
    \item Compute Shapley value $\phi_j = \frac{1}{M}\sum_{m=1}^M \phi_j^m$ %= \frac{1}{M} \sum_{m = 1}^M   \fh(\xjp ) -  \fh(\xjm ) $
  \end{enumerate}
%\pause
%Each $\phi_j^m$ is a random sample from the marginal contribution of feature $j$ for a sampled coalition introduced by $\tau$.
   
   %$$ \phi_j(\xv) = \frac{1}{|P|! \cdot n} \sum_{\tau \in \Pi} \sum_{i = 1}^n  \fh(\xv_{\Smj}, \xv_{\minusSmj}^{(i)}) - \fh(\xv_{\Sm}, \xv_{- \Sm}^{(i)})  $$
   
   % \vspace{0.25cm}
    %\tiny{Strumbelj, Erik, Igor Kononenko, Erik Strumbelj, and Igor Kononenko. 2014. $"$Explaining prediction models and individual predictions with feature contributions.$"$}

\end{frame}

\begin{frame}{Shapley value approximation - Illustration}

\begin{exampleblock}{Definition}
% \[
% \tikzmark{phi}\phi_{\tikzmark{j}j}(%\tikzmark{v}\fh,
% \tikzmark{x}\xv)=\frac{1}{M}\tikzmark{M}\sum_{m=1}^M \left[
% \fh_{\Sm \tikzmark{SJ}\cup j}
% \left(\xv_{\Sm \tikzmark{SJ}\cup j}\right)-
% \fh_{\tikzmark{S}\Sm}\left(\xv_{\tikzmark{S}\Sm}\right)\right]
% \]
$$
\tikzmark{phi}\phi_{\tikzmark{j}j}(%\tikzmark{v}\fh,
\tikzmark{x}\xv)=\frac{1}{M}\tikzmark{M}\sum_{m=1}^M \left[
\fh(\xv_{+j}\tikzmark{SJ}^{(m)}) -
\fh(\xv_{-j}\tikzmark{S}^{(m)})\right]
$$
\begin{tikzpicture}[
  remember picture,
  overlay,
  expl/.style={draw=blue,fill=white,rounded corners,text width=3.7cm},
  arrow/.style={blue,ultra thick,->,>=latex}
]
%%%% Explain Formula I
% \draw<2-3> [draw=white, fill=white, opacity=0]
%       (5.8,0) -- (11,0) -- (11,2) -- (5.8,2) --cycle;
% \node<1>[expl] 
%   (phiex) 
%   at (6,2cm)
%   {Shapley value of feat. $j$};
% \node<2>[expl] 
%   (jex) 
%   at (2,0cm)
%   {for feature $j$};
% \node<3>[expl] 
%   (vex) 
%   at (5,-0.7cm)
%   {$\fh$: pred. function};
\node<1>[expl] 
  (xex) 
  at (4,2cm)
  {$\xv$: obs. of interest};
% \draw<1>[arrow]
%   (phiex.south) to[out=270,in=90] ([xshift= 1ex, yshift=1.5ex]{pic cs:phi});  
% \draw<2>[arrow]
%   (jex.north) to[out=90,in=270] ([yshift=-0.5ex]{pic cs:j});  
% \draw<3>[arrow]
%   (vex.east) to[out=0,in=270] ([xshift= 1ex, yshift=-0.5ex]{pic cs:v});  
\draw<1>[arrow]
  (xex.south) to[out=270,in=90] ([xshift= 0.5ex, yshift=1.5ex]{pic cs:x}); 
  
 %%%% Explain Formula II
% \draw<3-5> [draw=white, fill=white, opacity=0.6]
%       (4,0) -- (6.8,0) -- (6.8,2) -- (4,2) --cycle;
\node<1>[expl] 
  (Sex) 
  at (9,2cm)
  {$\xv$ with feature values in $\Sm$ (other are replaced)};
\node<2>[expl] 
  (Sex) 
  at (5,2cm)
  {Contribution of feature $j$ to coalition $\Sm$};
 \node<1>[expl] 
  (SJex) 
  at (8,-0.8cm)
  {$\xv$ with feature values in $\Smj$};
  \draw<1>[arrow]
  (Sex.south) to[out=270,in=50] ([xshift= 1ex, yshift=2.5ex]{pic cs:S});
 \draw<2>[arrow]
  (Sex.east) to[out=0,in=90] ([xshift= 1ex, yshift=2.5ex]{pic cs:S});
  \draw<1>[arrow]
  (SJex.north) to[out=90,in=270] ([yshift=-1ex]{pic cs:SJ}); 
  \draw<2> [decorate,decoration={brace, amplitude=5pt,mirror,raise=4ex}]  (5.6,1.1) --  (8.85,1.1)
  node[midway,yshift=-3.4em]{\scriptsize $:= \Delta(j, \Sm)$};
  
  \draw<2> [draw=white, fill=white, opacity=0.6]
       (2.5,0) -- (5.5,0) -- (5.5,1.5) -- (2.5,1.5) --cycle;
  %%%% Explain Formula III
  \draw<3> [draw=white, fill=white, opacity=0.6]
       (2.5,0) -- (4.2,0) -- (4.2, 2) -- (2.5,2) --cycle;
  \draw<3> [draw=white, fill=white, opacity=0.6]
        (5.5,0) -- (10.5,0) -- (10.5,2) -- (5.5,2) --cycle;
  \node<3>[expl] 
  (Mex) 
  at (8,2cm)
  {average the contributions of feature $j$};
  \draw<3>[arrow]
  (Mex.west) to[out=180,in=50] ([xshift= 0.5ex, yshift=4ex]{pic cs:M}); 
\end{tikzpicture}
\end{exampleblock}
%\vspace{0.5cm}
\begin{itemize}
    \begin{onlyenv}<1>
    \vspace{50pt}
    % \item The Shapley value assigns a value to each feature $j$ according to the marginal contribution of each player in all possible coalitions
    \end{onlyenv}
    %\invisible<2>{\item The Shapley value assigns a value to each feature $j$ according to the marginal contribution of each player in all possible coalitions}
    %\begin{onlyenv}<3>
    %\item A value function $v(S): 2^{|P|}\mapsto \R$ describes the payout (or gain) achieved by any coalition $\forall S \subseteq P$. The value of the empty coalition must be zero: $v(\emptyset) = 0$.
    %\item The payout of coalition $S$ for observation $\xv$ is 
    %$$v(\xv_S) =  \fh_{S} (\xv_S) - \E (\fh(\xv))$$ 
    %i.e., the difference of the marginal prediction of $\xv_S$ and the average prediction.
    %\end{onlyenv}
    %\begin{onlyenv}<4>
    %\item Example observation from bike sharing data
    %\end{onlyenv}
    % Part II
    %\begin{onlyenv}<5>
    %\item $\Sm$ is a randomly selected set of features: $\Sm \subseteq P \setminus j$ where $P$ denotes the quantity of all features in $X$
    %\item Let $x_{\Sm}$ be a random chosen subset of features in $x_S$ that is hold fix
    %\end{onlyenv}
     %   \begin{onlyenv}<6>
    %\item Let $S_{\lnot m}$ denote the subset of $P$ that is not in $\Sm$.
    %\item Draw the values of all other features $x_{S_{\lnot m}}$ randomly from the set of available values of the regarding feature to calculate $v(x_{\Sm})$
    %\end{onlyenv}
    \begin{onlyenv}<2>
     \item $\Delta(j, \Sm) = \fh(\xjp) -
\fh(\xjm)$ is the marginal contribution of feature $j$ to coalition $\Sm$
    \item Here: Feature \textit{year} contributes +700 bike rentals if it joins coalition $\Sm = \{temp, hum\}$ %compared to the expected prediction conditioned on features in coalition $\Sm$ (while other features were taken from a random obs.)
    \end{onlyenv}
    \begin{onlyenv}<3>
    \item Compute marginal contribution of feature $j$ towards the prediction across all randomly drawn feature coalitions $S_1, \ldots , \Sm$
    \item Average all $M$ marginal contributions of feature $j$
    \item Shapley value $\phi_j$ is the payout of feature $j$, i.e., how much feature \textit{year} contributed to the overall prediction in bicycle counts of a specific observation $\xv$
    \end{onlyenv}
\end{itemize}
\vspace*{\fill}
%\vspace*{30pt}
\begin{center}
%\includegraphics<3>[width=0.5\textwidth]{figure_man/shapley_valuefct}
% Link https://docs.google.com/presentation/d/14FZZ4zk7IBZv6XnQA0wDVfCDhmjzf4np5uVj7KrIxXg/edit#slide=id.p
%\includegraphics<4>[page=1, width=1\textwidth]{figure_man/data_shapley}
%\includegraphics<5>[page=2, width=1\textwidth]{figure_man/data_shapley}
%\includegraphics<6>[page=3, width=1\textwidth]{figure_man/data_shapley}
%\includegraphics<7>[page=4, width=1\textwidth]{figure_man/data_shapley}
\includegraphics<1>[page=13, width=1\textwidth]{figure_man/data_shapley}
\includegraphics<2>[page=14, width=1\textwidth]{figure_man/data_shapley}
\includegraphics<3>[page=15, width=1\textwidth]{figure_man/data_shapley}
\end{center}

\end{frame}





\begin{frame}{Revisited: Axioms for Fair Attributions}
  We take the general axioms for Shapley Values and apply it to predictions:
  \vspace{0.25cm}
  \begin{itemize}[<+->]
  \itemsep1em
    \item \textbf{Efficiency}: Shapley values add up to the (centered) prediction: %. 
    %That means, unlike, e.g., LIME, we get a dense attribution, and not a sparse one.
    $\sum\nolimits_{j=1}^p\phi_j=\fh(\xv)-\E_{\xv}(\fh(X))$
    \item \textbf{Symmetry}: Two features $j$ and $k$ that contribute the same to the prediction get the same payout\\
    $\leadsto$ interaction effects between features are fairly divided \\
      $\fh_{S\cup\{j\}}(\xv_{\Scupj}) = \fh_{\Scupk}(\xv_{\Scupk})$ for all $S \subseteq P\setminus\{j,k\}$ then $\phi_j=\phi_k$
    \item \textbf{Dummy / Null Player}: Shapley value of a feature that does not influence the prediction is zero $\leadsto$ if a feature was not selected by the model (e.g., tree or LASSO), its Shapley value is zero  \\
      $\fh_{\Scupj}(\xv_{\Scupj})=\fhS(\xv_S)$ for all $S \subseteq P$ then $\phi_j=0$
    \item \textbf{Additivity}:  For a prediction with combined payouts, the
      payout is the sum of payouts: $\phi_j(v_1) + \phi_j(v_2)$ $\leadsto$ Shapley values for model ensembles can be combined
  \end{itemize}
\end{frame}



% \begin{frame}{Additional Estimation Trick}


%   The Shapley value can be estimated more efficiently when certain coalitions are always included in the computation, instead of random sampling:
%   \vspace{0.25cm}
%   \begin{itemize}
%   \itemsep1em
%     \item The coalitions with $S = \emptyset$ (i.e., $|S| = 0$) and $S = \{1, \ldots, p\} \setminus j$ have the highest weights in the Shapley value computation $\leadsto$ including them makes Shapley value more stable with fewer samples %Sample weights have to be adapted for the sampled coalitions afterwards.
%     \item Intuition: Adding a feature to the empty coalition gives information about the \textit{pure} first order effect of the feature, which is the effect without any interactions 
%     \item Adding the feature value to the complete set of feature values gives us the information about the total effect of a feature, which is the sum of the main effect and all interaction effects with other features
%     \item For coalition $S = \emptyset$, there are $0! (|P| - 0 - 1)! = 1 \cdot (|P| - 1)! = (p - 1)!$ orders, which is the same for $S = P \setminus \{j\}$: $|P \setminus \{j\}|! (|P| - |P \setminus \{j\}| - 1)! = (p - 1)! (p - (p-1) - 1)! = (p-1)!$
% \end{itemize}
%  \end{frame}

% \begin{frame}{Additional Estimation Trick}
% An example with $p = 5$ features:
% \vspace{0.25cm}
%     \begin{itemize}
%     \itemsep1em
%         \item There are $5! = 120$ orders in total
%         \item In $(5 - 1)! = 24$ orders, we added feature value $x_j$ to the empty set
%         \item In 24 orders, we added the feature value to the otherwise full feature set
%         \item That means with just two sets, we can already get $\frac{48}{120} = 0.4$ of the contributions to the Shapley value
%         \item Similarly, we could proceed with all coalitions of $\{S: |S| = 1\}$ and $\{S: |S| = p - 1\}$
%         \item When some coalitions are added \enquote{manually}, and the rest are sampled, we have to adapt the weights: Let $w$ be the weight of the \enquote{manually} sampled coalitions, $\hat{\phi}_{j,fixed}$ the part of the Shapley value with only the manual contributions and $\hat{\phi}_{j,sample}$ the Shapley value with the sampled coalitions, then the Shapley value is: $w \cdot \hat{\phi}_{j,fixed} + (1 - w) \hat{\phi}_{j,sample}$
%   \end{itemize}
% \end{frame}

% \begin{frame}{Additional Estimation Trick}
%       \begin{center}
%         \includegraphics[width=0.5\textwidth]{figure/shapley-weights}
%       \end{center}
% \end{frame}

\begin{frame}{Bike Sharing Dataset}

\begin{center}
\includegraphics[width=0.6\textwidth]{figure/shapley-bike.pdf}%{figure_man/bike-sharing03.png}%
\end{center}

\begin{itemize}
    \item Shapley values of observation $i = 200$ from the bike sharing data
    \item Difference between model prediction of this observation and the average prediction of the data is fairly distributed among the features (i.e., $4434 - 4507 \approx -73 $)
    \item Feature value temp = 28.5 has the most positive effect, with a contribution (increase of prediction) of about +400
\end{itemize}
\end{frame}

% \begin{frame}{Versions of the Shapley Value}

%   \begin{itemize}
%   \item KernelSHAP formulates the Shapley value solution as a regression problem using a specific kernel function. The authors show paralles to LIME and Deeplift.
%   \item TreeSHAP is a fast Shapley value computation method for tree-based models such as gradient boosted trees.
%  \end{itemize}
%     \tiny{Lundberg, Scott M., and Su-In Lee. "A Unified Approach to Interpreting Model Predictions." Advances in Neural Information Processing Systems 30 (2017): 4765-4774.}
%     \tiny{Lundberg, Scott M., Gabriel G. Erion, and Su-In Lee. "Consistent individualized feature attribution for tree ensembles." arXiv preprint arXiv:1802.03888 (2018).}
% \end{frame}

\begin{frame}{ADVANTAGES AND DISADVANTAGES}
	\textbf{Advantages:}
	\begin{itemize}
	 \item \textbf{Solid theoretical foundation} in game theory
        \item Prediction is \textbf{fairly distributed} among the feature values $\leadsto$ easy to interpret for a user
        \item \textbf{Contrastive explanations} that compare the prediction with the average prediction
	\end{itemize}
\vspace{0.25cm}
	\textbf{Disadvantages:}
	\begin{itemize}
		\item Without sampling, Shapley values need a lot of computing time to
		inspect all possible coalitions
		%\item The Shapley value of a feature value can be easily misinterpreted:
		%It is not the difference of the predicted value after removing the
		%feature from the model training; it is the contribution of a feature
		%value to the difference between the actual prediction and the mean
		%prediction, given the current set of features
		\item Like many other IML methods, Shapley values suffer from the
		inclusion of unrealistic data observations when features are correlated
	\end{itemize}



\end{frame}

\endlecture
\end{document}
