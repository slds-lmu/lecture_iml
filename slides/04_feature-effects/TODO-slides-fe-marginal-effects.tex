\documentclass[11pt,compress,t,notes=noshow, aspectratio=169, xcolor=table]{beamer}

\usepackage{../../style/lmu-lecture}
% Defines macros and environments
\input{../../style/common.tex}

\title{Interpretable Machine Learning}
% \author{LMU}
%\institute{\href{https://compstat-lmu.github.io/lecture_iml/}{compstat-lmu.github.io/lecture\_iml}}
\date{}

\begin{document}

\newcommand{\titlefigure}{figure_man/me_movement}
\newcommand{\learninggoals}{
\item Why parameter-based interpretations are not always possible for parametric models
\item How marginal effects can be used in such cases
\item Drawbacks of marginal effects
\item Model-agnostic applicability}

\lecturechapter{Marginal Effects}
\lecture{Interpretable Machine Learning}

\begin{frame}{Interpretation of Simple Models}

\begin{itemize}
\itemsep1em
\item LM: Change in $x_1$ by $\Delta x_1$ results in change in $y$ by $\Delta y = \Delta x_1 \cdot \theta_1$
%interpretation  characterized by feature coefficients:
\begin{equation*}
y = \theta_0 + \theta_1 x_1 + \dots + \theta_p x_p + \dots + \epsilon
\end{equation*}
%\item A change in $x_1$ by $\Delta x_1$ results in a change in $y$ by $\Delta y = \Delta x_1 \cdot \theta_1$
\item Default interpretations correspond to $\Delta x_1 = 1$, i.e., $\Delta y = \theta$
\item All under "ceteris paribus", i.e., all remaining features are kept constant
\item For polynomial models with higher-order or interaction terms, interpretations via single coefficients are not possible anymore, e.g.:
%\begin{equation*}

\medskip

\centerline{$y = \theta_0 + \theta_{1} x_1^2 + \theta_{2} x_2^2 + \theta_{1, 2} x_1 \cdot x_2 + \epsilon$}

\medskip

%\label{eq:poly_model}
%\end{equation*}
\begin{itemize}
%
\item Marginal effect of feature $x_1$ varies across different values for feature $x_2$ (and vice versa)
\item Interaction depends on values of another feature
%\item If $x_1$ changes, $y$ is affected by $\theta_1$ and $\theta_{1,2}$ 
\end{itemize}
\end{itemize}
\end{frame}

% \begin{frame}{Interpretations of Polynomial Models}


% \begin{itemize}
% \itemsep1em
% \item If higher-order terms or interactions are present, parameter-based interpretations are not possible anymore:
% \begin{equation}
% y = \theta_0 + \theta_{1} x_1^2 + \theta_{2} x_2^2 + \theta_{1, 2} x_1, x_2 + \epsilon
% \label{eq:poly_model}
% \end{equation}
% \item The isolated main effects of both features vary across different values
% \item The interaction depends on values of the remaining feature
% \item The marginal effect allows us to determine a feature effect nonetheless.
% \end{itemize}

% \end{frame}

\begin{frame}{Marginal Effects}

\begin{itemize}
%\itemsep2em
\item
Derivative ME: Derivative of $f$ w.r.t. feature. Compute via numeric differentiation
$$dME_j(x) = \frac{\partial f(x)}{\partial x_j} \approx \frac{f(x + h) - f(x - h)}{2h}$$
\item Less known definition based on forward differences: Change in predicted outcome due to a change in feature value (e.g., increasing a feature $x_j$ by $h_j$) $\Rightarrow$ forward ME (fME):
\begin{equation*}
fME_j(x, h_j) = f(x_1, \dots, x_j + h_j, \dots, x_p) - f(x)
\end{equation*}
\item Example: For model equation $y = \theta_0 + \theta_{1} x_1^2 + \theta_{2} x_2^2 + \theta_{1, 2} x_1 \cdot x_2 + \epsilon$
\begin{itemize}
\item dME of $x_1$ is $dME_1(x) = 2\theta_1 x_1 +  \theta_{1, 2} x_2$
\item fME of $x_1$ with step size $h_1 = 1$ is
$fME_1(x, h_1) = 2\theta_1 h_1^2 +  \theta_{1, 2} x_2 h_1$
\end{itemize}
\end{itemize}
\end{frame}


%%%
%------------------------------------------------------------
% \begin{frame}{Why Marginal Effects \emph{still} matter}
% \begin{itemize}
%   \item \textbf{Scalar answers}: FME/AME $=$ $\Delta\hat y$ per $\Delta x$ - easy to quote, store, regress on.  
%   \item \textbf{High-dimensional moves}: change several features at once\\
%   $\leadsto$ PD/ICE plots collapse beyond 2-D
%   \item \textbf{Categoricals included}: FME\(c_j\) = $\hat f(\text{new cat})-\hat f(\text{old})$ - no dummy coding.  
%   %\item \textbf{No feature-independence assumption}: we perturb the \emph{observed} point – avoids unrealistic combos that PD may sample.
%   % \item \textbf{Local trust score}: NLM \(\uparrow\) tells when the linear view holds (LLTR), something PD/ICE can’t quantify numerically.  
%   % \item \textbf{Statistical workhorses}: averages (AME/cAME), CIs, hypothesis tests, subgroup trees – all built on numeric MEs.  
%   \item \textbf{Efficiency}: two predictions per observation vs.\ grid\(\times n\) evaluations for PD.  
% \end{itemize}
% %\vspace{0.2cm}
% %\alert{Plots help you \emph{see}; Marginal Effects give numbers you can \emph{use}.}


% \begin{block}{Key points}
% \begin{enumerate}[1.]
% \item \textbf{PD / ICE} excel at \alert{exploration and storytelling}:  you \emph{see} how predictions evolve.
% \item \textbf{Forward Marginal Effects} deliver \alert{concise, numeric,
%       statistically-tractable} answers that
%       regulators, tables, and downstream pipelines need:
%       \begin{itemize}
%           \item single numbers (AME, cAME) with CIs;
%           \item high-dimensional interventions possible;
%           \item no independence assumption, no surrogate model.
%       \end{itemize}
% \end{enumerate}
% \end{block}

% \begin{center}
% \Large\(\Rightarrow\) \textbf{Use both: plots to explore, MEs to quantify.}
% \end{center}
% \end{frame}
% --------------------------------------------------------------- %
%  Slide – Why Marginal Effects still matter (Concise, Formal)
% --------------------------------------------------------------- %
\begin{frame}{Why Marginal Effects \emph{still} matter}

\begin{itemize}\setlength\itemsep{0.4em}
  \item \textbf{Scalar summary:}  
        $\text{FME}_j = \widehat f(\xv+h\mathbf e_j)-\widehat f(\xv)$ - interpretable, testable, storable.
        
  \item \textbf{Dimension-agnostic:}  
        Effective with many features, incl.\ categorical; avoids PD/ICE's dimensionality constraints.
        
  \item \textbf{Model-faithful:}  
        Local to $\xv$; preserves interactions without assumptions.

  \item \textbf{Efficient:}  
        Two predictions per feature suffice.
  \item \textbf{Conclusion:}
  \begin{itemize}
      \item ME yield concise, rigorous insights
      \item Complementary to PD/ICE visualizations
  \end{itemize}
\end{itemize}

\end{frame}

% --------------------------------------------------------------- %
%  Slide – Clinician use-case: Marginal Effects vs ICE/PD
% --------------------------------------------------------------- %
\begin{frame}{Use-case: Scalar vs. Visual Estimation}

\textbf{Clinician’s questions}
\begin{itemize}\setlength\itemsep{0.3em}
  \item \emph{"What if this patient’s systolic BP increases by 10 mmHg?"}
  \item \emph{"What if BP increases by 10 mmHg \& LDL by 15 mg/dL?"}
\end{itemize}

\vspace{0.5em}
\textbf{Route A – ICE / PD}
\begin{itemize}
  \item Visualize effect along 1-D or 2-D feature grid.
  \item Manual interpretation of curve/surface deltas.
  \item \(\rightarrow\) local, visual, interaction-limited.
\end{itemize}

\vspace{0.3em}
\textbf{Route B – Forward Marginal Effect}: $\mathrm{FME}_{\Delta\xv}
  = \widehat f(\xv + h) - \widehat f(\xv)$
\begin{itemize}
  \item \textbf{1-D case:} \(\Delta\xv = (10, 0) \;\Rightarrow\; \mathbf{+3\;\text{pp}}\)
  \item \textbf{2-D case:} \(\Delta\xv = (10, 15) \;\Rightarrow\; \mathbf{+4.1\;\text{pp}}\)
  \item One scalar answer per query, extensible to higher dimensions.
\end{itemize}

\end{frame}

% % ---------------------------------------------------------------- %
% %  Slide 1 – Clinician use-case: two interpretation routes
% % ---------------------------------------------------------------- %
% \begin{frame}{Use-case}

% \textbf{Clinician’s question}  
% \emph{"If this patient’s systolic blood pressure rises by 10 mmHg,
% how will her predicted heart-attack risk change?"}

% \vspace{0.6em}
% \begin{columns}[t,onlytextwidth]

% % ---------- left column: ICE / PD vs FME ------------------------ %
% \begin{column}{1\textwidth}
% \textbf{Route A – ICE / PD}  
% \begin{itemize}
%   \item Draw ICE curve for the patient across BP grid.
%   \item Read the distance between 120 and 130 mmHg.  
%         \(\rightarrow\) visual, manual, 1-D only.
% \end{itemize}

% \medskip
% \textbf{Route B – Forward Marginal Effect}  (\(h=10\))
% \[
% \mathrm{FME}_{\Delta\text{BP}=10}
%   \;=\; \widehat f(\text{BP}+10,\xv_{-\text{BP}})
%   -   \widehat f(\xv)
%   \;=\; \mathbf{+3\;\text{pp}}
% \]
% \begin{itemize}
%   \item One scalar answer: "+3 percentage-points risk".
%   \item Same formula works for any multi-feature change.
% \end{itemize}
% \end{column}

% % ---------- right column: space for figure if desired ------------ %
% % \begin{column}{0.42\textwidth}
% % \begin{center}
% % %\includegraphics[width=\linewidth]{figure_man/bp_ice_vs_fme_placeholder} % optional
% % \end{center}
% % \end{column}

% \end{columns}
% \end{frame}

% \begin{frame}{Use-case}

% \textbf{Clinician’s question}  
% \emph{"If this patient’s systolic blood pressure rises by 10 mmHg, and LDL cholesterol increases by 15 mg/dL, how will her predicted heart-attack risk change?"}

% \vspace{0.6em}
% \begin{columns}[t,onlytextwidth]

% \begin{column}{1\textwidth}
% \textbf{Route A – ICE / PD}  
% \begin{itemize}
%   \item Examine ICE curves for BP and LDL separately.
%   \item Joint effect estimation requires visual extrapolation.
%   \item \(\rightarrow\) limited to pairwise views, ignores interaction.
% \end{itemize}

% \medskip
% \textbf{Route B – Forward Marginal Effect}  (\(h = (\Delta\text{BP}, \Delta\text{LDL})\))
% \[
% \mathrm{FME}_{\Delta\xv}
%   = \widehat f(\xv + h) - \widehat f(\xv)
%   = \mathbf{+4.1\;\text{pp}}
% \]
% \begin{itemize}
%   \item One scalar for the combined directional effect.
%   \item Automatically incorporates nonlinear interactions.
% \end{itemize}
% \end{column}

% \end{columns}
% \end{frame}


% Relation to ICE and PD
\begin{frame}{Relation to ICE and PD}
\begin{itemize}
\item \textbf{Individual Conditional Expectation (ICE)}:
\begin{itemize}
\item Visualizes predictions for an observation across a range of feature values.
\item FME corresponds to vertical differences between points on an ICE curve.
\end{itemize}
\item \textbf{Partial Dependence (PD)}:
\begin{itemize}
\item Shows average predictions across a range of feature values.
\item AME is equivalent to vertical differences on PD for linear models.
\end{itemize}
\item \textbf{Advantages of FMEs}:
\begin{itemize}
\item Provide exact change in prediction.
\item Applicable to high-dimensional feature changes.
\item Quantifiable and not limited to visual interpretation.
\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Derivative versus Forward Difference}

%%%

\begin{columns}[T]
\begin{column}{0.6\textwidth}
\begin{itemize}
\itemsep1em
\item Derivative of non-linear prediction functions substantially differ at different points \\
$\Rightarrow$ dME is not suited
\item fME corresponds to a movement on prediction function, indicating changes in predicted outcome regardless of the function's shape\\
$\Rightarrow$ fME better suited for non-linear prediction functions
\item However, with both variants, we lose information about the prediction function along the finite difference
\end{itemize}
\end{column}
\begin{column}{0.4\textwidth}
 \includegraphics[width = \textwidth]{figure_man/derivative_me_error.png}
\end{column}
\end{columns}

\end{frame}

% \begin{frame}{Derivative versus Forward Difference}
% \begin{figure}
%   \includegraphics[width = 0.5\textwidth]{figure_man/derivative_me_error.png}
% \end{figure}
% \end{frame}

\begin{frame}{Additive Recovery}

\begin{itemize}
\itemsep1em
\item Both variants only recover terms within prediction function that depend on feature(s) of interest
\item Consider a prediction function $\widehat{f}(x) = ax_1 + bx_2$. It follows that:
\begin{align*}
dME_1(x) &= a \\
fME_1(x, h_1) &= ah_1
\end{align*}
\item MEs remove effects of other features that are linked additively %, regardless of how many remaining features exist, and their effect structure
\end{itemize}

\end{frame}


\begin{frame}{Model-Agnostic Applicability}

\begin{itemize}
\itemsep1em
\item MEs were historically used to interpret GLMs, however, they can be used as model-agnostic interpretation tools for non-parametric models 
%\item As fMEs are better suited for non-linear prediction functions, they are better suited for interpreting ML models
\item fMEs correspond to an exploration of the prediction function and are better suited for non-linear prediction functions
\item With fMEs, we can also use multivariate changes in feature values to explore the prediction surface in various directions simultaneously
\item Note: Shape of the prediction function may vary considerably along the forward difference, i.e., an fME with half the step size may not result in half the fME
\end{itemize}

\end{frame}


% \begin{frame}{Model-Agnostic Applicability}

% \begin{itemize}
% \itemsep2em
% \item MEs are traditionally used to interpret parametric models such as GLMs. However, both dME and fME can be used as model-agnostic interpretation tools for non-parametric models. As the fME is better suited for non-linear prediction functions, it is the natural choice for black box ML models.
% \item The fME essentially correspond to an exploration of the prediction function. We can also use multivariate changes in feature values to explore the prediction surface in various directions simultaneously.
% \item One needs to keep in mind that the shape of the prediction function may vary considerably along the forward difference, i.e., an fME with half the step size may not result in half the fME.
% \end{itemize}

% \end{frame}





\endlecture
\end{document}
