\documentclass[11pt,compress,t,notes=noshow, aspectratio=169, xcolor=table]{beamer}

\usepackage{../../style/lmu-lecture}
% Defines macros and environments
\input{../../style/common.tex}

\title{Interpretable Machine Learning}
% \author{LMU}
%\institute{\href{https://compstat-lmu.github.io/lecture_iml/}{compstat-lmu.github.io/lecture\_iml}}
\date{}

\begin{document}

% \newcommand{\titlefigure}{figure/sample-dgp-2d.pdf}
\newcommand{\learninggoals}{
\item Understand structure of tabular data in ML
\item Understand difference between target and features
\item Understand difference between labeled and unlabeled data
\item Know concept of data-generating process}

\lecturechapter{Shapley Values Aggregation}
\lecture{Interpretable Machine Learning}

\begin{vbframe}{Shapley Values Aggregations}

  \begin{itemize}
    \item Shapley Values are local explanations.
    \item When computed for many observations, can be aggregated to global explanations.
      \begin{itemize}
        \item Feature Importance
        \item Summary plots
        \item dependence plots
        \item Interactions plots
        \item clustered Shapley values
      \end{itemize}
  \end{itemize}
\end{vbframe}

\begin{vbframe}{Feature Importance}
\end{vbframe}

\begin{vbframe}{Summary Plot}
\end{vbframe}

\begin{vbframe}{Dependence Plot}
\end{vbframe}

\begin{vbframe}{Interaction Plots}
\end{vbframe}

\begin{vbframe}{Clustered Shapley values}
\end{vbframe}





\endlecture
\end{document}
