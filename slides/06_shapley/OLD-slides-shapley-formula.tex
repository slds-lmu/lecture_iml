\documentclass[11pt,compress,t,notes=noshow, aspectratio=169, xcolor=table]{beamer}

\usepackage{../../style/lmu-lecture}
% Defines macros and environments
\input{../../style/common.tex}

\title{Interpretable Machine Learning}
% \author{LMU}
%\institute{\href{https://compstat-lmu.github.io/lecture_iml/}{compstat-lmu.github.io/lecture\_iml}}
\date{}

\begin{document}
\begin{vbframe}{Shapley Values Aggregations}

\begin{exampleblock}{Definition}
\[
\tikzmark{phi}\phi_{\tikzmark{j}j}(\tikzmark{v}v, \tikzmark{x}x)=\frac{1}{M}\tikzmark{M}\sum_{m=1}^M \left[v\left(x_{S_m \tikzmark{SJ}\cup j} \right)-v\left(x_{\tikzmark{S}S_m}\right)\right]
\]
\begin{tikzpicture}[
  remember picture,
  overlay,
  expl/.style={draw=blue,fill=white,rounded corners,text width=3cm},
  arrow/.style={blue,ultra thick,->,>=latex}
]
%%%% Explain Formula I
\draw<2-4> [draw=white, fill=white, opacity=0.6]
       (6.2,0) -- (11,0) -- (11,2) -- (6.2,2) --cycle;
\node<2>[expl] 
  (phiex) 
  at (4,2cm)
  {$\phi$: The Shapley value};
\node<2>[expl] 
  (jex) 
  at (2,0cm)
  {for feature $j$};
\node<3>[expl] 
  (vex) 
  at (5,0cm)
  {$v$: value function};
\node<4>[expl] 
  (xex) 
  at (6,2cm)
  {$x$: Input data (a single observation)};
\draw<2>[arrow]
  (phiex.south) to[out=270,in=90] ([xshift= 1ex, yshift=1.5ex]{pic cs:phi});  
\draw<2>[arrow]
  (jex.north) to[out=90,in=270] ([yshift=-0.5ex]{pic cs:j});  
\draw<3>[arrow]
  (vex.east) to[out=90,in=270] ([xshift= 1ex, yshift=-0.5ex]{pic cs:v});  
\draw<4>[arrow]
  (xex.west) to[out=180,in=135] ([xshift= 0.5ex, yshift=1ex]{pic cs:x}); 
  
 %%%% Explain Formula II
\draw<5-8> [draw=white, fill=white, opacity=0.6]
       (4,0) -- (7.2,0) -- (7.2,2) -- (4,2) --cycle;
\node<5>[expl] 
  (Sex) 
  at (10,2cm)
  {$x_{S_m}$: A Subset of $x_S$};
\node<6>[expl] 
  (Sex) 
  at (13,0.5cm)
  {$v(x_{S_m})$: The contribution of $x_{S_m}$ to the average prediction $\E (\fh(\xv))$};
 \node<7>[expl] 
  (SJex) 
  at (10,-0.5cm)
  {$x_{S_m \cup j}$: A Subset of $x$ including feature $j$};
  \draw<5>[arrow]
  (Sex.south) to[out=270,in=90] ([xshift= 1ex, yshift=1.5ex]{pic cs:S});
 \draw<6>[arrow]
  (Sex.west) to[out=90,in=90] ([xshift= 1ex, yshift=1.5ex]{pic cs:S});
  \draw<7>[arrow]
  (SJex.north) to[out=90,in=270] ([yshift=-0.5ex]{pic cs:SJ}); 
  \draw<8> [decorate,decoration={brace, amplitude=5pt,mirror,raise=4ex}]  (7.4,1.1) --  (10.5,1.1)
  node[midway,yshift=-3.5em]{$:= \Delta(j, S_m)$};
  %%%% Explain Formula III
  \draw<9-> [draw=white, fill=white, opacity=0.6]
       (4,0) -- (6.3,0) -- (6.3,2) -- (4,2) --cycle;
  \draw<9-> [draw=white, fill=white, opacity=0.6]
        (7.3,0) -- (10.5,0) -- (10.5,2) -- (7.3,2) --cycle;
  \node<9>[expl] 
  (Mex) 
  at (10,2cm)
  {$\frac{1}{M}\sum$: Average the contribution of feature $j$};
  \draw<9>[arrow]
  (Mex.west) to[out=180,in=135] ([xshift= 0.5ex, yshift=2ex]{pic cs:M}); 
\end{tikzpicture}
\end{exampleblock}
\vspace{0.5cm}
\begin{itemize}
    \begin{onlyenv}<2>
    \item The Shapley value assigns a value to each feature $j$ according to the marginal contribution of each player in all possible coalitions $S$.
    \end{onlyenv}
    \begin{onlyenv}<3>
    \item A value function $v(S): 2^{|P|}\mapsto \R$ describes the payout (or gain) achieved by any coalition $\forall S \subseteq P$. The value of the empty coalition must be zero: $v(\emptyset) = 0$.
    \item The payout of coalition $S$ for observation $\xv$ is 
    $$v(\xv_S) =  \fh_{S} (\xv_S) - \E (\fh(\xv))$$ 
    i.e., the difference of the marginal prediction of $\xv_S$ and the average prediction.
    \end{onlyenv}
    \begin{onlyenv}<4>
    \item Example observation from bike sharing data
    \end{onlyenv}
    % Part II
    \begin{onlyenv}<5>
    \item $S_m$ is a randomly selected set of features: $S_m \subseteq P \setminus j$ where $P$ denotes the quantity of all features in $X$
    \item Let $x_{S_m}$ be a random chosen subset of features in $x_S$ that is hold fix.
    \end{onlyenv}
        \begin{onlyenv}<6>
    \item Let $S_{\lnot m}$ denote the subset of $P$ that is not in $S_m$.
    \item Draw the values of all other features $x_{S_{\lnot m}}$ randomly from the set of available values of the regarding feature to calculate $v(x_{S_m})$.
    \end{onlyenv}
    \begin{onlyenv}<8>
     \item $\Delta(j, S_m) = v(x_{S \cup j}) - v(x_{S})$ is the marginal contribution of player $j$ to coalition $S$.
    \item In this Subset $S_m$ the variable \textit{year} contributes +17 bike rentals compared to a random guess of the variable.
    \end{onlyenv}
    \begin{onlyenv}<9>
    \item Finally, average the marginal contribution of feature $j$ towards the prediction
    across all randomly drawn feature coalitions $S_1, \ldots , S_m$.
    \item The resulting Shapley value $\phi_j$ tells us what the payout feature $j$ is, i.e., how the feature \textit{year} contributes to the overall prediction in bicicle counts of a specific observation $S$.
    \end{onlyenv}
\end{itemize}
\vspace*{\fill}
\begin{center}
\includegraphics<3>[width=0.5\textwidth]{figure_man/shapley_valuefct}
% Link https://docs.google.com/presentation/d/14FZZ4zk7IBZv6XnQA0wDVfCDhmjzf4np5uVj7KrIxXg/edit#slide=id.p
\includegraphics<4>[page=1, width=1\textwidth]{figure_man/data_shapley}
\includegraphics<5>[page=2, width=1\textwidth]{figure_man/data_shapley}
\includegraphics<6>[page=3, width=1\textwidth]{figure_man/data_shapley}
\includegraphics<7>[page=4, width=1\textwidth]{figure_man/data_shapley}
\includegraphics<8>[page=5, width=1\textwidth]{figure_man/data_shapley}
\includegraphics<9>[page=6, width=1\textwidth]{figure_man/data_shapley}
\end{center}

\end{vbframe}
\endlecture
\end{document}